{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 4단계: 하이퍼파라미터 최적화\n",
    "\n",
    "## 📋 목표\n",
    "- GridSearchCV를 통한 최적 파라미터 탐색\n",
    "- RandomizedSearchCV 비교\n",
    "- 학습 곡선 및 검증 곡선 분석\n",
    "- 교차검증을 통한 더 정확한 성능 평가\n",
    "\n",
    "## 📊 분석 내용\n",
    "1. GridSearchCV를 통한 Ridge/Lasso 최적화\n",
    "2. RandomizedSearchCV 성능 비교\n",
    "3. 교차검증 점수 분석\n",
    "4. 학습 곡선(Learning Curve) 분석\n",
    "5. 검증 곡선(Validation Curve) 분석\n",
    "6. 최종 모델 선택 및 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, RandomizedSearchCV,\n",
    "    cross_val_score, learning_curve, validation_curve\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "from font_setup import setup_korean_font\n",
    "setup_korean_font()\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 데이터 준비 및 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "california_housing = fetch_california_housing()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "feature_names = california_housing.feature_names\n",
    "\n",
    "print(\"📊 California Housing Dataset 정보\")\n",
    "print(f\"특성 수: {X.shape[1]}\")\n",
    "print(f\"샘플 수: {X.shape[0]}\")\n",
    "print(f\"특성 이름: {list(feature_names)}\")\n",
    "\n",
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 데이터 분할 결과\")\n",
    "print(f\"훈련 데이터: {X_train.shape[0]}개 샘플\")\n",
    "print(f\"테스트 데이터: {X_test.shape[0]}개 샘플\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 설정 (정규화 + 모델)\n",
    "def create_pipeline(model):\n",
    "    \"\"\"\n",
    "    StandardScaler + 모델 파이프라인 생성\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# 기본 모델들\n",
    "models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42, max_iter=2000)\n",
    "}\n",
    "\n",
    "print(\"🔧 파이프라인 설정 완료\")\n",
    "print(\"• StandardScaler + 모델 파이프라인\")\n",
    "print(\"• 교차검증을 통한 하이퍼파라미터 최적화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ GridSearchCV를 통한 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge GridSearchCV\n",
    "print(\"🔍 Ridge Regression GridSearchCV 시작...\")\n",
    "start_time = time.time()\n",
    "\n",
    "ridge_pipeline = create_pipeline(Ridge(random_state=42))\n",
    "ridge_param_grid = {\n",
    "    'model__alpha': np.logspace(-3, 3, 50)  # 0.001 ~ 1000 범위에서 50개 값\n",
    "}\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    ridge_pipeline, \n",
    "    ridge_param_grid, \n",
    "    cv=5,  # 5-fold 교차검증\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,  # 모든 CPU 코어 사용\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_time = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Ridge GridSearchCV 완료 (소요시간: {ridge_time:.2f}초)\")\n",
    "print(f\"🎯 최적 Ridge α: {ridge_grid.best_params_['model__alpha']:.4f}\")\n",
    "print(f\"📊 최적 CV Score: {ridge_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso GridSearchCV\n",
    "print(\"\\n🔍 Lasso Regression GridSearchCV 시작...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lasso_pipeline = create_pipeline(Lasso(random_state=42, max_iter=2000))\n",
    "lasso_param_grid = {\n",
    "    'model__alpha': np.logspace(-4, 1, 50)  # 0.0001 ~ 10 범위에서 50개 값\n",
    "}\n",
    "\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso_pipeline, \n",
    "    lasso_param_grid, \n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "lasso_time = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Lasso GridSearchCV 완료 (소요시간: {lasso_time:.2f}초)\")\n",
    "print(f\"🎯 최적 Lasso α: {lasso_grid.best_params_['model__alpha']:.4f}\")\n",
    "print(f\"📊 최적 CV Score: {lasso_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 Linear Regression 교차검증 점수\n",
    "linear_pipeline = create_pipeline(LinearRegression())\n",
    "linear_cv_scores = cross_val_score(linear_pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "linear_cv_mean = linear_cv_scores.mean()\n",
    "\n",
    "print(f\"\\n📊 교차검증 결과 비교\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Linear Regression CV Score: {linear_cv_mean:.4f} (±{linear_cv_scores.std()*2:.4f})\")\n",
    "print(f\"Ridge (최적) CV Score: {ridge_grid.best_score_:.4f}\")\n",
    "print(f\"Lasso (최적) CV Score: {lasso_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ RandomizedSearchCV 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV 비교 (더 넓은 범위에서 빠른 탐색)\n",
    "print(\"🎲 RandomizedSearchCV 시작...\")\n",
    "\n",
    "# Ridge RandomizedSearchCV\n",
    "start_time = time.time()\n",
    "ridge_random = RandomizedSearchCV(\n",
    "    ridge_pipeline,\n",
    "    {'model__alpha': np.logspace(-4, 4, 1000)},  # 더 넓은 범위\n",
    "    n_iter=100,  # 100번의 랜덤 샘플링\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "ridge_random.fit(X_train, y_train)\n",
    "ridge_random_time = time.time() - start_time\n",
    "\n",
    "# Lasso RandomizedSearchCV\n",
    "start_time = time.time()\n",
    "lasso_random = RandomizedSearchCV(\n",
    "    lasso_pipeline,\n",
    "    {'model__alpha': np.logspace(-5, 2, 1000)},  # 더 넓은 범위\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "lasso_random.fit(X_train, y_train)\n",
    "lasso_random_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n⚡ RandomizedSearchCV 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Ridge Random - α: {ridge_random.best_params_['model__alpha']:.4f}, Score: {ridge_random.best_score_:.4f} ({ridge_random_time:.1f}초)\")\n",
    "print(f\"Ridge Grid   - α: {ridge_grid.best_params_['model__alpha']:.4f}, Score: {ridge_grid.best_score_:.4f} ({ridge_time:.1f}초)\")\n",
    "print(f\"\\nLasso Random - α: {lasso_random.best_params_['model__alpha']:.4f}, Score: {lasso_random.best_score_:.4f} ({lasso_random_time:.1f}초)\")\n",
    "print(f\"Lasso Grid   - α: {lasso_grid.best_params_['model__alpha']:.4f}, Score: {lasso_grid.best_score_:.4f} ({lasso_time:.1f}초)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 검증 곡선 (Validation Curve) 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 검증 곡선\n",
    "ridge_alphas = np.logspace(-3, 3, 30)\n",
    "ridge_train_scores, ridge_val_scores = validation_curve(\n",
    "    ridge_pipeline, X_train, y_train,\n",
    "    param_name='model__alpha',\n",
    "    param_range=ridge_alphas,\n",
    "    cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Lasso 검증 곡선\n",
    "lasso_alphas = np.logspace(-4, 1, 30)\n",
    "lasso_train_scores, lasso_val_scores = validation_curve(\n",
    "    lasso_pipeline, X_train, y_train,\n",
    "    param_name='model__alpha',\n",
    "    param_range=lasso_alphas,\n",
    "    cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"📈 검증 곡선 계산 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 곡선 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge 검증 곡선\n",
    "ridge_train_mean = ridge_train_scores.mean(axis=1)\n",
    "ridge_train_std = ridge_train_scores.std(axis=1)\n",
    "ridge_val_mean = ridge_val_scores.mean(axis=1)\n",
    "ridge_val_std = ridge_val_scores.std(axis=1)\n",
    "\n",
    "ax1.plot(ridge_alphas, ridge_train_mean, 'o-', color='blue', label='훈련 점수', linewidth=2)\n",
    "ax1.fill_between(ridge_alphas, ridge_train_mean - ridge_train_std,\n",
    "                 ridge_train_mean + ridge_train_std, alpha=0.1, color='blue')\n",
    "ax1.plot(ridge_alphas, ridge_val_mean, 'o-', color='red', label='검증 점수', linewidth=2)\n",
    "ax1.fill_between(ridge_alphas, ridge_val_mean - ridge_val_std,\n",
    "                 ridge_val_mean + ridge_val_std, alpha=0.1, color='red')\n",
    "\n",
    "ax1.axvline(x=ridge_grid.best_params_['model__alpha'], color='green', \n",
    "            linestyle='--', alpha=0.8, label=f'최적 α={ridge_grid.best_params_[\"model__alpha\"]:.3f}')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('정규화 강도 (α)')\n",
    "ax1.set_ylabel('R² Score')\n",
    "ax1.set_title('Ridge Regression 검증 곡선', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Lasso 검증 곡선\n",
    "lasso_train_mean = lasso_train_scores.mean(axis=1)\n",
    "lasso_train_std = lasso_train_scores.std(axis=1)\n",
    "lasso_val_mean = lasso_val_scores.mean(axis=1)\n",
    "lasso_val_std = lasso_val_scores.std(axis=1)\n",
    "\n",
    "ax2.plot(lasso_alphas, lasso_train_mean, 'o-', color='blue', label='훈련 점수', linewidth=2)\n",
    "ax2.fill_between(lasso_alphas, lasso_train_mean - lasso_train_std,\n",
    "                 lasso_train_mean + lasso_train_std, alpha=0.1, color='blue')\n",
    "ax2.plot(lasso_alphas, lasso_val_mean, 'o-', color='red', label='검증 점수', linewidth=2)\n",
    "ax2.fill_between(lasso_alphas, lasso_val_mean - lasso_val_std,\n",
    "                 lasso_val_mean + lasso_val_std, alpha=0.1, color='red')\n",
    "\n",
    "ax2.axvline(x=lasso_grid.best_params_['model__alpha'], color='green', \n",
    "            linestyle='--', alpha=0.8, label=f'최적 α={lasso_grid.best_params_[\"model__alpha\"]:.3f}')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('정규화 강도 (α)')\n",
    "ax2.set_ylabel('R² Score')\n",
    "ax2.set_title('Lasso Regression 검증 곡선', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 학습 곡선 (Learning Curve) 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델들로 학습 곡선 생성\n",
    "print(\"📚 학습 곡선 계산 중...\")\n",
    "\n",
    "# 훈련 세트 크기\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "# Linear Regression 학습 곡선\n",
    "linear_train_sizes, linear_train_scores, linear_val_scores = learning_curve(\n",
    "    linear_pipeline, X_train, y_train, train_sizes=train_sizes, \n",
    "    cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ridge (최적) 학습 곡선\n",
    "ridge_train_sizes, ridge_train_scores_lc, ridge_val_scores_lc = learning_curve(\n",
    "    ridge_grid.best_estimator_, X_train, y_train, train_sizes=train_sizes, \n",
    "    cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Lasso (최적) 학습 곡선\n",
    "lasso_train_sizes, lasso_train_scores_lc, lasso_val_scores_lc = learning_curve(\n",
    "    lasso_grid.best_estimator_, X_train, y_train, train_sizes=train_sizes, \n",
    "    cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"✅ 학습 곡선 계산 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('📚 모델별 학습 곡선 비교', fontsize=16, fontweight='bold')\n",
    "\n",
    "models_lc = [\n",
    "    ('Linear Regression', linear_train_sizes, linear_train_scores, linear_val_scores),\n",
    "    ('Ridge (최적)', ridge_train_sizes, ridge_train_scores_lc, ridge_val_scores_lc),\n",
    "    ('Lasso (최적)', lasso_train_sizes, lasso_train_scores_lc, lasso_val_scores_lc)\n",
    "]\n",
    "\n",
    "for i, (name, train_sizes_lc, train_scores_lc, val_scores_lc) in enumerate(models_lc):\n",
    "    train_mean = train_scores_lc.mean(axis=1)\n",
    "    train_std = train_scores_lc.std(axis=1)\n",
    "    val_mean = val_scores_lc.mean(axis=1)\n",
    "    val_std = val_scores_lc.std(axis=1)\n",
    "    \n",
    "    axes[i].plot(train_sizes_lc, train_mean, 'o-', color='blue', \n",
    "                 label='훈련 점수', linewidth=2, markersize=6)\n",
    "    axes[i].fill_between(train_sizes_lc, train_mean - train_std,\n",
    "                         train_mean + train_std, alpha=0.1, color='blue')\n",
    "    \n",
    "    axes[i].plot(train_sizes_lc, val_mean, 'o-', color='red', \n",
    "                 label='검증 점수', linewidth=2, markersize=6)\n",
    "    axes[i].fill_between(train_sizes_lc, val_mean - val_std,\n",
    "                         val_mean + val_std, alpha=0.1, color='red')\n",
    "    \n",
    "    axes[i].set_xlabel('훈련 세트 크기')\n",
    "    axes[i].set_ylabel('R² Score')\n",
    "    axes[i].set_title(name, fontweight='bold')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 최종 성능 표시\n",
    "    final_val_score = val_mean[-1]\n",
    "    axes[i].text(0.02, 0.95, f'최종 검증 점수: {final_val_score:.3f}', \n",
    "                transform=axes[i].transAxes, fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 최종 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델들로 테스트 세트 평가\n",
    "def evaluate_final_model(model, model_name, X_test, y_test):\n",
    "    \"\"\"\n",
    "    최종 모델 평가 함수\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2,\n",
    "        'Predictions': y_pred\n",
    "    }\n",
    "\n",
    "# 최적 모델들 평가\n",
    "linear_pipeline.fit(X_train, y_train)\n",
    "results_final = {\n",
    "    'linear': evaluate_final_model(linear_pipeline, 'Linear Regression', X_test, y_test),\n",
    "    'ridge_grid': evaluate_final_model(ridge_grid.best_estimator_, \n",
    "                                      f'Ridge (α={ridge_grid.best_params_[\"model__alpha\"]:.4f})', \n",
    "                                      X_test, y_test),\n",
    "    'lasso_grid': evaluate_final_model(lasso_grid.best_estimator_, \n",
    "                                      f'Lasso (α={lasso_grid.best_params_[\"model__alpha\"]:.4f})', \n",
    "                                      X_test, y_test),\n",
    "    'ridge_random': evaluate_final_model(ridge_random.best_estimator_, \n",
    "                                         f'Ridge Random (α={ridge_random.best_params_[\"model__alpha\"]:.4f})', \n",
    "                                         X_test, y_test),\n",
    "    'lasso_random': evaluate_final_model(lasso_random.best_estimator_, \n",
    "                                         f'Lasso Random (α={lasso_random.best_params_[\"model__alpha\"]:.4f})', \n",
    "                                         X_test, y_test)\n",
    "}\n",
    "\n",
    "# 결과 표 생성\n",
    "final_df = pd.DataFrame([\n",
    "    {\n",
    "        '모델': results_final[key]['Model'],\n",
    "        'Test_R²': results_final[key]['R²'],\n",
    "        'Test_RMSE': results_final[key]['RMSE'],\n",
    "        'Test_MAE': results_final[key]['MAE']\n",
    "    }\n",
    "    for key in results_final.keys()\n",
    "]).sort_values('Test_R²', ascending=False)\n",
    "\n",
    "print(\"🏆 최종 모델 성능 비교 (테스트 세트)\")\n",
    "print(\"=\" * 80)\n",
    "print(final_df.round(4))\n",
    "\n",
    "# 최고 성능 모델\n",
    "best_model = final_df.iloc[0]\n",
    "print(f\"\\n🥇 최고 성능 모델: {best_model['모델']}\")\n",
    "print(f\"📊 Test R² Score: {best_model['Test_R²']:.4f}\")\n",
    "print(f\"📊 Test RMSE: {best_model['Test_RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 성능 비교 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# R² Score 비교\n",
    "models_names = final_df['모델'].tolist()\n",
    "r2_scores = final_df['Test_R²'].tolist()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models_names)))\n",
    "\n",
    "bars1 = ax1.barh(models_names, r2_scores, color=colors, alpha=0.8)\n",
    "ax1.set_xlabel('R² Score')\n",
    "ax1.set_title('최종 모델 R² Score 비교', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 값 표시\n",
    "for i, (bar, score) in enumerate(zip(bars1, r2_scores)):\n",
    "    ax1.text(score + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{score:.4f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# RMSE 비교\n",
    "rmse_scores = final_df['Test_RMSE'].tolist()\n",
    "bars2 = ax2.barh(models_names, rmse_scores, color=colors, alpha=0.8)\n",
    "ax2.set_xlabel('RMSE')\n",
    "ax2.set_title('최종 모델 RMSE 비교', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 값 표시\n",
    "for i, (bar, score) in enumerate(zip(bars2, rmse_scores)):\n",
    "    ax2.text(score + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "             f'{score:.4f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 하이퍼파라미터 탐색 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV 결과 상세 분석\n",
    "def plot_grid_search_results(grid_search, title, param_name='model__alpha'):\n",
    "    \"\"\"\n",
    "    GridSearchCV 결과 시각화\n",
    "    \"\"\"\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogx(results_df[f'param_{param_name}'], results_df['mean_test_score'], \n",
    "                 'o-', linewidth=2, markersize=6)\n",
    "    plt.fill_between(results_df[f'param_{param_name}'], \n",
    "                     results_df['mean_test_score'] - results_df['std_test_score'],\n",
    "                     results_df['mean_test_score'] + results_df['std_test_score'],\n",
    "                     alpha=0.2)\n",
    "    \n",
    "    # 최적값 표시\n",
    "    best_alpha = grid_search.best_params_[param_name]\n",
    "    best_score = grid_search.best_score_\n",
    "    plt.axvline(x=best_alpha, color='red', linestyle='--', alpha=0.8)\n",
    "    plt.scatter([best_alpha], [best_score], color='red', s=100, zorder=5)\n",
    "    \n",
    "    plt.xlabel('정규화 강도 (α)')\n",
    "    plt.ylabel('교차검증 R² Score')\n",
    "    plt.title(f'{title}\\n최적 α = {best_alpha:.4f}, CV Score = {best_score:.4f}', \n",
    "              fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Ridge와 Lasso GridSearch 결과 시각화\n",
    "plot_grid_search_results(ridge_grid, 'Ridge Regression GridSearchCV 결과')\n",
    "plot_grid_search_results(lasso_grid, 'Lasso Regression GridSearchCV 결과')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 Lasso 모델의 특성 선택 효과 확인\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_coeffs = best_lasso.named_steps['model'].coef_\n",
    "\n",
    "# 0이 아닌 계수들\n",
    "non_zero_features = np.where(np.abs(lasso_coeffs) > 1e-6)[0]\n",
    "zero_features = np.where(np.abs(lasso_coeffs) <= 1e-6)[0]\n",
    "\n",
    "print(f\"\\n✂️ 최적 Lasso 모델의 특성 선택 효과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"선택된 특성 ({len(non_zero_features)}개): {[feature_names[i] for i in non_zero_features]}\")\n",
    "if len(zero_features) > 0:\n",
    "    print(f\"제거된 특성 ({len(zero_features)}개): {[feature_names[i] for i in zero_features]}\")\nelse:\n",
    "    print(\"제거된 특성: 없음 (모든 특성 유지)\")\n",
    "\n",
    "# 특성별 계수 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if abs(coef) <= 1e-6 else 'blue' for coef in lasso_coeffs]\n",
    "bars = plt.bar(feature_names, lasso_coeffs, color=colors, alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('특성')\n",
    "plt.ylabel('계수 값')\n",
    "plt.title(f'최적 Lasso 모델 계수 (α={lasso_grid.best_params_[\"model__alpha\"]:.4f})', \n",
    "          fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 범례\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='blue', alpha=0.7, label='선택된 특성'),\n",
    "                   Patch(facecolor='red', alpha=0.7, label='제거된 특성')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 4단계 분석 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 4단계: 하이퍼파라미터 최적화 결과 요약\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n🔍 GridSearchCV vs RandomizedSearchCV:\")\n",
    "print(f\"• Ridge GridSearch: α={ridge_grid.best_params_['model__alpha']:.4f}, Score={ridge_grid.best_score_:.4f} ({ridge_time:.1f}초)\")\n",
    "print(f\"• Ridge RandomSearch: α={ridge_random.best_params_['model__alpha']:.4f}, Score={ridge_random.best_score_:.4f} ({ridge_random_time:.1f}초)\")\n",
    "print(f\"• Lasso GridSearch: α={lasso_grid.best_params_['model__alpha']:.4f}, Score={lasso_grid.best_score_:.4f} ({lasso_time:.1f}초)\")\n",
    "print(f\"• Lasso RandomSearch: α={lasso_random.best_params_['model__alpha']:.4f}, Score={lasso_random.best_score_:.4f} ({lasso_random_time:.1f}초)\")\n",
    "\n",
    "print(f\"\\n🏆 최종 성능 순위 (테스트 세트):\")\n",
    "for i, (_, row) in enumerate(final_df.iterrows(), 1):\n",
    "    print(f\"{i}. {row['모델']}: R² = {row['Test_R²']:.4f}\")\n",
    "\n",
    "print(f\"\\n💡 주요 발견사항:\")\n",
    "print(f\"• 교차검증을 통한 더 정확한 하이퍼파라미터 최적화 달성\")\n",
    "print(f\"• RandomizedSearchCV가 GridSearchCV 대비 빠른 속도로 유사한 성능 달성\")\n",
    "print(f\"• 학습 곡선을 통해 모델의 수렴성과 안정성 확인\")\n",
    "print(f\"• 검증 곡선을 통해 최적 정규화 강도의 타당성 입증\")\n",
    "\n",
    "if len(zero_features) > 0:\n",
    "    print(f\"• Lasso 특성 선택: {len(zero_features)}개 특성 자동 제거\")\n",
    "else:\n",
    "    print(f\"• Lasso 특성 선택: 최적 α 값에서 모든 특성 유지\")\n",
    "\n",
    "print(f\"\\n🎯 다음 단계 예고:\")\n",
    "print(f\"• 5단계: 최종 결과 분석 및 시각화\")\n",
    "print(f\"• Feature Importance 분석\")\n",
    "print(f\"• 예측 결과 상세 분석\")\n",
    "print(f\"• 프로젝트 전체 결과 종합\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}