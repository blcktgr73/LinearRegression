{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 3단계: 모델 구현 및 비교\n",
    "\n",
    "## 📋 목표\n",
    "- Linear Regression 기본 모델\n",
    "- Ridge Regression (L2 정규화)\n",
    "- Lasso Regression (L1 정규화)\n",
    "- 모델별 성능 지표 비교 (MSE, MAE, R²)\n",
    "\n",
    "## 📊 분석 내용\n",
    "1. 기본 Linear Regression 모델 구현\n",
    "2. Ridge Regression (L2 정규화) 구현\n",
    "3. Lasso Regression (L1 정규화) 구현\n",
    "4. 정규화 강도(alpha) 값에 따른 성능 변화\n",
    "5. 특성 계수 변화 분석\n",
    "6. 모델별 과적합 방지 효과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "from font_setup import setup_korean_font\n",
    "setup_korean_font()\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "california_housing = fetch_california_housing()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "feature_names = california_housing.feature_names\n",
    "\n",
    "print(\"📊 California Housing Dataset 정보\")\n",
    "print(f\"특성 수: {X.shape[1]}\")\n",
    "print(f\"샘플 수: {X.shape[0]}\")\n",
    "print(f\"특성 이름: {list(feature_names)}\")\n",
    "\n",
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 정규화 적용 (Ridge, Lasso에서 중요!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n📊 데이터 분할 결과\")\n",
    "print(f\"훈련 데이터: {X_train.shape[0]}개 샘플\")\n",
    "print(f\"테스트 데이터: {X_test.shape[0]}개 샘플\")\n",
    "print(\"✅ StandardScaler 정규화 적용 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ 모델별 구현 및 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    모델 훈련 및 평가 함수\n",
    "    \"\"\"\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Train_MSE': train_mse,\n",
    "        'Test_MSE': test_mse,\n",
    "        'Train_RMSE': np.sqrt(train_mse),\n",
    "        'Test_RMSE': np.sqrt(test_mse),\n",
    "        'Train_MAE': train_mae,\n",
    "        'Test_MAE': test_mae,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'Overfitting': train_r2 - test_r2,  # 과적합 정도\n",
    "        'Predictions': y_test_pred,\n",
    "        'Coefficients': model.coef_ if hasattr(model, 'coef_') else None\n",
    "    }\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "results = {}\n",
    "\n",
    "print(\"🤖 모델별 훈련 및 평가 시작\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression (기본 모델)\n",
    "print(\"1️⃣ Linear Regression 훈련...\")\n",
    "linear_model = LinearRegression()\n",
    "results['linear'] = evaluate_model(\n",
    "    linear_model, X_train_scaled, X_test_scaled, y_train, y_test, 'Linear Regression'\n",
    ")\n",
    "print(f\"   ✅ 완료 - Test R²: {results['linear']['Test_R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ridge Regression (L2 정규화) - 여러 alpha 값 테스트\n",
    "print(\"\\n2️⃣ Ridge Regression 훈련...\")\n",
    "alpha_values = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    ridge_model = Ridge(alpha=alpha, random_state=42)\n",
    "    model_name = f'Ridge (α={alpha})'\n",
    "    results[f'ridge_{alpha}'] = evaluate_model(\n",
    "        ridge_model, X_train_scaled, X_test_scaled, y_train, y_test, model_name\n",
    "    )\n",
    "    print(f\"   ✅ α={alpha} - Test R²: {results[f'ridge_{alpha}']['Test_R2']:.4f}\")\n",
    "\n",
    "# 최적 Ridge 모델 선택 (가장 높은 Test R²)\n",
    "best_ridge_key = max([k for k in results.keys() if k.startswith('ridge')], \n",
    "                     key=lambda x: results[x]['Test_R2'])\n",
    "best_ridge_alpha = float(best_ridge_key.split('_')[1])\n",
    "print(f\"   🎯 최적 Ridge α: {best_ridge_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lasso Regression (L1 정규화) - 여러 alpha 값 테스트\n",
    "print(\"\\n3️⃣ Lasso Regression 훈련...\")\n",
    "alpha_values = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    lasso_model = Lasso(alpha=alpha, random_state=42, max_iter=2000)\n",
    "    model_name = f'Lasso (α={alpha})'\n",
    "    results[f'lasso_{alpha}'] = evaluate_model(\n",
    "        lasso_model, X_train_scaled, X_test_scaled, y_train, y_test, model_name\n",
    "    )\n",
    "    print(f\"   ✅ α={alpha} - Test R²: {results[f'lasso_{alpha}']['Test_R2']:.4f}\")\n",
    "\n",
    "# 최적 Lasso 모델 선택\n",
    "best_lasso_key = max([k for k in results.keys() if k.startswith('lasso')], \n",
    "                     key=lambda x: results[x]['Test_R2'])\n",
    "best_lasso_alpha = float(best_lasso_key.split('_')[1])\n",
    "print(f\"   🎯 최적 Lasso α: {best_lasso_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ 모델 성능 비교 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 모델들의 성능 비교 표 생성\n",
    "comparison_models = [\n",
    "    'linear',\n",
    "    best_ridge_key,\n",
    "    best_lasso_key\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        '모델': results[key]['Model'],\n",
    "        'Train_R²': results[key]['Train_R2'],\n",
    "        'Test_R²': results[key]['Test_R2'],\n",
    "        'Train_RMSE': results[key]['Train_RMSE'],\n",
    "        'Test_RMSE': results[key]['Test_RMSE'],\n",
    "        'Over fitting': results[key]['Overfitting']\n",
    "    }\n",
    "    for key in comparison_models\n",
    "])\n",
    "\n",
    "print(\"📊 주요 모델 성능 비교\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# 최고 성능 모델 확인\n",
    "best_model = comparison_df.loc[comparison_df['Test_R²'].idxmax()]\n",
    "print(f\"\\n🏆 최고 성능 모델: {best_model['모델']} (Test R² = {best_model['Test_R²']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('📊 모델별 성능 지표 비교', fontsize=16, fontweight='bold')\n",
    "\n",
    "models = [results[key]['Model'] for key in comparison_models]\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "\n",
    "# R² Score 비교\n",
    "train_r2 = [results[key]['Train_R2'] for key in comparison_models]\n",
    "test_r2 = [results[key]['Test_R2'] for key in comparison_models]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, train_r2, width, label='Train R²', alpha=0.7, color='skyblue')\n",
    "axes[0, 0].bar(x + width/2, test_r2, width, label='Test R²', alpha=0.7, color='orange')\n",
    "axes[0, 0].set_xlabel('모델')\n",
    "axes[0, 0].set_ylabel('R² Score')\n",
    "axes[0, 0].set_title('R² Score 비교', fontweight='bold')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(models, rotation=15)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE 비교\n",
    "train_rmse = [results[key]['Train_RMSE'] for key in comparison_models]\n",
    "test_rmse = [results[key]['Test_RMSE'] for key in comparison_models]\n",
    "\n",
    "axes[0, 1].bar(x - width/2, train_rmse, width, label='Train RMSE', alpha=0.7, color='skyblue')\n",
    "axes[0, 1].bar(x + width/2, test_rmse, width, label='Test RMSE', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_xlabel('모델')\n",
    "axes[0, 1].set_ylabel('RMSE')\n",
    "axes[0, 1].set_title('RMSE 비교', fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(models, rotation=15)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 과적합 정도 비교\n",
    "overfitting = [results[key]['Overfitting'] for key in comparison_models]\n",
    "\n",
    "bars = axes[1, 0].bar(models, overfitting, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('모델')\n",
    "axes[1, 0].set_ylabel('과적합 정도 (Train R² - Test R²)')\n",
    "axes[1, 0].set_title('과적합 정도 비교', fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=15)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "for bar, value in zip(bars, overfitting):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + (0.001 if height > 0 else -0.001),\n",
    "                   f'{value:.4f}', ha='center', va='bottom' if height > 0 else 'top', fontweight='bold')\n",
    "\n",
    "# Alpha 값에 따른 성능 변화 (Ridge)\n",
    "ridge_alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "ridge_test_r2 = [results[f'ridge_{alpha}']['Test_R2'] for alpha in ridge_alphas]\n",
    "\n",
    "axes[1, 1].plot(ridge_alphas, ridge_test_r2, 'o-', color='blue', linewidth=2, markersize=6, label='Ridge')\n",
    "\n",
    "# Lasso 추가\n",
    "lasso_alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "lasso_test_r2 = [results[f'lasso_{alpha}']['Test_R2'] for alpha in lasso_alphas]\n",
    "\n",
    "axes[1, 1].plot(lasso_alphas, lasso_test_r2, 's-', color='green', linewidth=2, markersize=6, label='Lasso')\n",
    "\n",
    "axes[1, 1].set_xlabel('정규화 강도 (α)')\n",
    "axes[1, 1].set_ylabel('Test R² Score')\n",
    "axes[1, 1].set_title('정규화 강도에 따른 성능 변화', fontweight='bold')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 특성 계수 분석 - 정규화 효과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 계수 비교\n",
    "coefficients_df = pd.DataFrame({\n",
    "    '특성': feature_names,\n",
    "    'Linear': results['linear']['Coefficients'],\n",
    "    'Ridge': results[best_ridge_key]['Coefficients'],\n",
    "    'Lasso': results[best_lasso_key]['Coefficients']\n",
    "})\n",
    "\n",
    "print(\"🔍 모델별 특성 계수 비교\")\n",
    "print(\"=\" * 60)\n",
    "print(coefficients_df.round(4))\n",
    "\n",
    "# Lasso에서 0이 된 특성 확인\n",
    "zero_features = coefficients_df[coefficients_df['Lasso'] == 0]['특성'].tolist()\n",
    "if zero_features:\n",
    "    print(f\"\\n✂️ Lasso에서 제거된 특성: {zero_features}\")\n",
    "else:\n",
    "    print(f\"\\n📊 Lasso에서 모든 특성이 유지됨\")\n",
    "\n",
    "print(f\"\\n🎯 특성 선택 효과:\")\n",
    "print(f\"• Linear/Ridge: 모든 특성 사용 ({len(feature_names)}개)\")\n",
    "print(f\"• Lasso: {len(feature_names) - len(zero_features)}개 특성 사용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계수 크기 비교 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# 계수 절댓값 비교\n",
    "x = np.arange(len(feature_names))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar(x - width, np.abs(coefficients_df['Linear']), width, \n",
    "        label='Linear', alpha=0.7, color='lightcoral')\n",
    "ax1.bar(x, np.abs(coefficients_df['Ridge']), width, \n",
    "        label=f'Ridge (α={best_ridge_alpha})', alpha=0.7, color='lightblue')\n",
    "ax1.bar(x + width, np.abs(coefficients_df['Lasso']), width, \n",
    "        label=f'Lasso (α={best_lasso_alpha})', alpha=0.7, color='lightgreen')\n",
    "\n",
    "ax1.set_xlabel('특성')\n",
    "ax1.set_ylabel('계수 절댓값')\n",
    "ax1.set_title('모델별 특성 계수 절댓값 비교', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(feature_names, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 계수 원본값 비교 (양수/음수 구분)\n",
    "ax2.bar(x - width, coefficients_df['Linear'], width, \n",
    "        label='Linear', alpha=0.7, color='lightcoral')\n",
    "ax2.bar(x, coefficients_df['Ridge'], width, \n",
    "        label=f'Ridge (α={best_ridge_alpha})', alpha=0.7, color='lightblue')\n",
    "ax2.bar(x + width, coefficients_df['Lasso'], width, \n",
    "        label=f'Lasso (α={best_lasso_alpha})', alpha=0.7, color='lightgreen')\n",
    "\n",
    "ax2.set_xlabel('특성')\n",
    "ax2.set_ylabel('계수 값')\n",
    "ax2.set_title('모델별 특성 계수 원본값 비교', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(feature_names, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 예측 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제값 vs 예측값 산점도\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('🎯 실제값 vs 예측값 비교', fontsize=16, fontweight='bold')\n",
    "\n",
    "model_keys = ['linear', best_ridge_key, best_lasso_key]\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "titles = ['Linear Regression', f'Ridge (α={best_ridge_alpha})', f'Lasso (α={best_lasso_alpha})']\n",
    "\n",
    "for i, (key, color, title) in enumerate(zip(model_keys, colors, titles)):\n",
    "    axes[i].scatter(y_test, results[key]['Predictions'], alpha=0.5, color=color)\n",
    "    axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[i].set_xlabel('실제값')\n",
    "    axes[i].set_ylabel('예측값')\n",
    "    axes[i].set_title(f'{title}\\nR² = {results[key][\"Test_R2\"]:.4f}', fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차 분석\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('📊 잔차 분석 (Residual Analysis)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (key, color, title) in enumerate(zip(model_keys, colors, titles)):\n",
    "    residuals = y_test - results[key]['Predictions']\n",
    "    axes[i].scatter(results[key]['Predictions'], residuals, alpha=0.5, color=color)\n",
    "    axes[i].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[i].set_xlabel('예측값')\n",
    "    axes[i].set_ylabel('잔차 (실제값 - 예측값)')\n",
    "    axes[i].set_title(f'{title}', fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 잔차의 표준편차 표시\n",
    "    std_residual = np.std(residuals)\n",
    "    axes[i].text(0.02, 0.98, f'잔차 표준편차: {std_residual:.3f}', \n",
    "                transform=axes[i].transAxes, fontsize=10, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 정규화 경로 분석 (Regularization Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge와 Lasso의 정규화 경로 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge 정규화 경로\n",
    "alphas_ridge = np.logspace(-2, 2, 50)\n",
    "ridge_coeffs = []\n",
    "\n",
    "for alpha in alphas_ridge:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_coeffs.append(ridge.coef_)\n",
    "\n",
    "ridge_coeffs = np.array(ridge_coeffs).T\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax1.plot(alphas_ridge, ridge_coeffs[i], label=feature, linewidth=2)\n",
    "\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('정규화 강도 (α)')\n",
    "ax1.set_ylabel('계수 값')\n",
    "ax1.set_title('Ridge 정규화 경로', fontweight='bold')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(x=best_ridge_alpha, color='red', linestyle='--', alpha=0.7, label=f'최적 α={best_ridge_alpha}')\n",
    "\n",
    "# Lasso 정규화 경로\n",
    "alphas_lasso = np.logspace(-3, 1, 50)\n",
    "lasso_coeffs = []\n",
    "\n",
    "for alpha in alphas_lasso:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=2000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_coeffs.append(lasso.coef_)\n",
    "\n",
    "lasso_coeffs = np.array(lasso_coeffs).T\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax2.plot(alphas_lasso, lasso_coeffs[i], label=feature, linewidth=2)\n",
    "\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('정규화 강도 (α)')\n",
    "ax2.set_ylabel('계수 값')\n",
    "ax2.set_title('Lasso 정규화 경로', fontweight='bold')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=best_lasso_alpha, color='red', linestyle='--', alpha=0.7, label=f'최적 α={best_lasso_alpha}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 3단계 분석 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 3단계: 모델 구현 및 비교 결과 요약\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 최종 성능 순위:\")\n",
    "performance_ranking = comparison_df.sort_values('Test_R²', ascending=False)\n",
    "for i, (_, row) in enumerate(performance_ranking.iterrows(), 1):\n",
    "    print(f\"{i}. {row['모델']}: R² = {row['Test_R²']:.4f}, RMSE = {row['Test_RMSE']:.4f}\")\n",
    "\n",
    "print(\"\\n🔍 주요 발견사항:\")\n",
    "\n",
    "# 과적합 분석\n",
    "min_overfitting = comparison_df.loc[comparison_df['Over fitting'].idxmin()]\n",
    "print(f\"• 과적합 방지 효과: {min_overfitting['모델']} (과적합 정도: {min_overfitting['Over fitting']:.4f})\")\n",
    "\n",
    "# 특성 선택 효과\n",
    "if zero_features:\n",
    "    print(f\"• Lasso 특성 선택: {len(zero_features)}개 특성 제거 ({', '.join(zero_features)})\")\nelse:\n",
    "    print(f\"• Lasso 특성 선택: 모든 특성 유지 (α 값이 작아서 제거 효과 미미)\")\n",
    "\n",
    "# 정규화 효과\n",
    "linear_coeff_sum = np.sum(np.abs(results['linear']['Coefficients']))\n",
    "ridge_coeff_sum = np.sum(np.abs(results[best_ridge_key]['Coefficients']))\n",
    "lasso_coeff_sum = np.sum(np.abs(results[best_lasso_key]['Coefficients']))\n",
    "\n",
    "print(f\"\\n💡 정규화 효과:\")\n",
    "print(f\"• 계수 크기 합계:\")\n",
    "print(f\"  - Linear: {linear_coeff_sum:.3f}\")\n",
    "print(f\"  - Ridge: {ridge_coeff_sum:.3f} ({((ridge_coeff_sum/linear_coeff_sum-1)*100):+.1f}%)\")\n",
    "print(f\"  - Lasso: {lasso_coeff_sum:.3f} ({((lasso_coeff_sum/linear_coeff_sum-1)*100):+.1f}%)\")\n",
    "\n",
    "print(f\"\\n🎯 다음 단계 예고:\")\n",
    "print(f\"• 4단계: GridSearchCV를 통한 하이퍼파라미터 최적화\")\n",
    "print(f\"• 교차검증을 통한 더 정확한 최적 α 값 탐색\")\n",
    "print(f\"• 학습 곡선과 검증 곡선 분석\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}